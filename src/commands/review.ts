/**
 * Handler for the 'review' command - now supports both V1 and V2 workflows.
 */
import { PrismaClient } from '@prisma/client';
import { getAppWithConfig } from '../graph/workflow';
import { GitHubMethod } from '../index';
import { v4 as uuidv4 } from 'uuid';
import ora from 'ora';
import chalk from 'chalk';
import fs from 'fs';
import path from 'path';

/**
 * Generates a comprehensive markdown report from the review state
 */
const generateMarkdownReport = (state: any, taskId: string, prUrl: string): string => {
  const timestamp = new Date().toISOString();
  const prDetails = state.pr_details || {};
  
  // Handle both workflow types: CLI workflow uses analyzed_files, advanced workflow uses file_results
  const analyzedFiles = state.analyzed_files || {};
  const fileResults = state.file_results || {};
  
  // Count total files analyzed from both sources
  const analyzedFilesCount = Object.keys(analyzedFiles).length;
  const fileResultsCount = Object.keys(fileResults).length;
  const totalFileCount = analyzedFilesCount + fileResultsCount;
  
  // Extract owner/repo from URL for cleaner display
  const urlMatch = prUrl.match(/github\.com\/([^/]+)\/([^/]+)\/pull\/(\d+)/);
  const owner = urlMatch ? urlMatch[1] : 'unknown';
  const repo = urlMatch ? urlMatch[2] : 'unknown';
  const prNumber = urlMatch ? urlMatch[3] : 'unknown';
  
  let markdown = `# ğŸ“Š Hikmapr PR Review Report

## ğŸ“‹ Pull Request Information

| Field | Value |
|-------|-------|
| **Repository** | \`${owner}/${repo}\` |
| **PR Number** | #${prNumber} |
| **PR Title** | ${prDetails.title || 'No title'} |
| **PR URL** | [${prUrl}](${prUrl}) |
| **Review Date** | ${new Date(timestamp).toLocaleString()} |
| **Task ID** | \`${taskId}\` |
| **Files Analyzed** | ${totalFileCount} |

## ğŸ“ PR Description

${prDetails.body || '*No description provided*'}

---

## ğŸ” File Analysis Summary

`;

  // Add individual file analyses
  if (totalFileCount > 0) {
    markdown += `### Files Reviewed (${totalFileCount})\n\n`;
    
    // Handle CLI workflow analyzed_files (simple string analyses)
    for (const [fileName, analysis] of Object.entries(analyzedFiles)) {
      markdown += `#### ğŸ“ \`${fileName}\`\n\n`;
      markdown += `${analysis || '*No analysis available*'}\n\n`;
      markdown += `---\n\n`;
    }
    
    // Handle advanced workflow file_results (structured FileAnalysisResult objects)
    for (const [fileName, result] of Object.entries(fileResults)) {
      const fileResult = result as any; // Type assertion since we're dealing with any
      markdown += `#### ğŸ“ \`${fileName}\`\n\n`;
      
      if (fileResult.overall_risk) {
        markdown += `**Risk Level:** ${fileResult.overall_risk}\n`;
      }
      if (fileResult.total_issues !== undefined) {
        markdown += `**Issues Found:** ${fileResult.total_issues}\n`;
      }
      if (fileResult.total_chunks !== undefined) {
        markdown += `**Chunks Analyzed:** ${fileResult.total_chunks}\n`;
      }
      
      markdown += `\n**Analysis:**\n`;
      markdown += `${fileResult.file_synthesis || '*No synthesis available*'}\n\n`;
      
      if (fileResult.recommendations && fileResult.recommendations.length > 0) {
        markdown += `**Recommendations:**\n`;
        fileResult.recommendations.forEach((rec: string, index: number) => {
          markdown += `${index + 1}. ${rec}\n`;
        });
        markdown += `\n`;
      }
      
      markdown += `---\n\n`;
    }
  } else {
    markdown += `*No files were analyzed*\n\n`;
  }

  // Add final report
  markdown += `## ğŸ¯ Overall Assessment\n\n`;
  markdown += `${state.final_report || '*No final report generated*'}\n\n`;

  // Add footer
  markdown += `---\n\n`;
  markdown += `*Report generated by [Hikmapr](https://github.com/foyzulkarim/hikma-pr) on ${new Date(timestamp).toLocaleString()}*\n`;
  
  return markdown;
};

/**
 * Saves the markdown report to a file
 */
const saveMarkdownReport = (markdown: string, prUrl: string, taskId: string): string => {
  // Create reports directory if it doesn't exist
  const reportsDir = path.join(process.cwd(), 'reports');
  if (!fs.existsSync(reportsDir)) {
    fs.mkdirSync(reportsDir, { recursive: true });
  }
  
  // Generate filename based on repo and PR number with full timestamp
  const urlMatch = prUrl.match(/github\.com\/([^/]+)\/([^/]+)\/pull\/(\d+)/);
  const owner = urlMatch ? urlMatch[1] : 'unknown';
  const repo = urlMatch ? urlMatch[2] : 'unknown';
  const prNumber = urlMatch ? urlMatch[3] : 'unknown';
  
  // Create a detailed timestamp: YYYY-MM-DD-HHMMSS
  const now = new Date();
  const date = now.toISOString().split('T')[0]; // YYYY-MM-DD
  const time = now.toTimeString().split(' ')[0].replace(/:/g, ''); // HHMMSS
  const timestamp = `${date}-${time}`;
  
  const filename = `${owner}-${repo}-PR${prNumber}-${timestamp}-${taskId.slice(0, 8)}.md`;
  const filepath = path.join(reportsDir, filename);
  
  // Write the file
  fs.writeFileSync(filepath, markdown, 'utf8');
  
  return filepath;
};

export const reviewCommandHandler = async (prUrl: string, prisma: PrismaClient, githubMethod: GitHubMethod) => {
  const taskId = uuidv4();
  console.log(chalk.bold.cyan(`\nğŸš€ Starting Hikmapr Multi-Pass Analysis`));
  console.log(chalk.blue(`ğŸ“ Task ID: ${chalk.yellow(taskId)}`));
  console.log(chalk.blue(`ğŸ”— PR URL: ${chalk.yellow(prUrl)}`));
  console.log(chalk.blue(`ğŸ”¬ Using Advanced Multi-Pass Analysis Architecture`));

  // Use the advanced multi-pass analysis workflow
  const { app, config: workflowConfig } = getAppWithConfig();
  
  const methodInfo = 'ğŸ”¬ Multi-Pass Analysis: 4 specialized passes per chunk with hierarchical synthesis';
  console.log(chalk.gray(methodInfo));
  console.log(chalk.gray(`ğŸ“‹ Smart filtering â†’ Recursive chunking â†’ 4-pass analysis â†’ Synthesis`));
  console.log(chalk.gray(`ğŸ”§ Workflow configured with recursion limit: ${workflowConfig.recursionLimit}`));

  const config = {
    configurable: {
      thread_id: taskId,
    },
    // Apply the workflow configuration to handle large number of files
    ...workflowConfig,
  };

  // Initial state
  const initialState = {
    pr_url: prUrl,
    task_id: taskId,
  };

  console.log(chalk.blue(`ğŸ’¾ Saving initial state to database...`));
  // Save initial state to the database
  await prisma.review.create({
    data: {
      id: taskId,
      prUrl: prUrl,
      state: initialState,
    },
  });
  console.log(chalk.green(`âœ… Initial state saved`));

  let lastState: any = {};
  let currentSpinner: any = null;
  
  console.log(chalk.bold.magenta(`\nğŸ”„ Starting workflow execution...\n`));
  
  try {
    for await (const event of await app.stream(initialState, config)) {
      // Fix: Access the state directly from the event
      const state = Object.values(event)[0] as any;
      
      // Properly merge both analyzed_files (CLI workflow) and file_results (advanced workflow)
      const currentAnalyzedFiles = lastState.analyzed_files || {};
      const newAnalyzedFiles = state.analyzed_files || {};
      const mergedAnalyzedFiles = { ...currentAnalyzedFiles, ...newAnalyzedFiles };
      
      const currentFileResults = lastState.file_results || {};
      const newFileResults = state.file_results || {};
      const mergedFileResults = { ...currentFileResults, ...newFileResults };
      
      // Preserve accumulated state by merging with lastState
      lastState = { 
        ...lastState, 
        ...state,
        analyzed_files: mergedAnalyzedFiles,
        file_results: mergedFileResults
      };
      
      // Handle both workflow types for progress tracking
      const analyzedFiles = state.analyzed_files || {};
      const fileResults = state.file_results || {};
      const filesToReview = state.files_to_review || [];
      const filesToProcess = state.files_to_process || [];
      
      // Save individual file analyses to database if new analyses are added
      // Handle CLI workflow analyzed_files (simple string analyses)
      if (state.analyzed_files && Object.keys(state.analyzed_files).length > 0) {
        for (const [fileName, analysis] of Object.entries(state.analyzed_files)) {
          // Check if this file analysis already exists to avoid duplicates
          const existingAnalysis = await prisma.fileAnalysis.findUnique({
            where: {
              reviewId_fileName: {
                reviewId: taskId,
                fileName: fileName
              }
            }
          });
          
          if (!existingAnalysis && typeof analysis === 'string') {
            console.log(chalk.gray(`ğŸ’¾ Saving CLI file analysis for: ${fileName}`));
            await prisma.fileAnalysis.create({
              data: {
                reviewId: taskId,
                fileName: fileName,
                analysis: analysis,
                diffSize: analysis.length, // Store the analysis length as a proxy for diff size
              }
            });
            console.log(chalk.green(`âœ… CLI file analysis saved for: ${fileName}`));
          }
        }
      }
      
      // Handle advanced workflow file_results (structured FileAnalysisResult objects)
      if (state.file_results && Object.keys(state.file_results).length > 0) {
        for (const [fileName, result] of Object.entries(state.file_results)) {
          // Check if this file analysis already exists to avoid duplicates
          const existingAnalysis = await prisma.fileAnalysis.findUnique({
            where: {
              reviewId_fileName: {
                reviewId: taskId,
                fileName: fileName
              }
            }
          });
          
          if (!existingAnalysis && result && typeof result === 'object') {
            const fileResult = result as any;
            const analysisText = fileResult.file_synthesis || 'No synthesis available';
            console.log(chalk.gray(`ğŸ’¾ Saving advanced file analysis for: ${fileName}`));
            await prisma.fileAnalysis.create({
              data: {
                reviewId: taskId,
                fileName: fileName,
                analysis: analysisText,
                diffSize: analysisText.length,
              }
            });
            console.log(chalk.green(`âœ… Advanced file analysis saved for: ${fileName}`));
          }
        }
      }
      
      // Update progress based on workflow state
      const totalAnalyzedFiles = Object.keys(analyzedFiles).length + Object.keys(fileResults).length;
      const totalFilesToProcess = filesToReview.length + filesToProcess.length;
      
      if(state.pr_details && !state.files_to_review && !state.filtered_files) {
          if (currentSpinner) currentSpinner.succeed();
          console.log(chalk.green(`\nâœ… PR Details fetched successfully`));
          currentSpinner = ora('Getting changed files list...').start();
      } else if ((filesToReview.length > 0 || filesToProcess.length > 0) && totalAnalyzedFiles === 0) {
          if (currentSpinner) currentSpinner.succeed();
          const totalFiles = filesToReview.length || filesToProcess.length;
          console.log(chalk.green(`\nâœ… Found ${totalFiles} files to analyze`));
          const filesList = filesToReview.length > 0 ? filesToReview : filesToProcess;
          console.log(chalk.blue(`ğŸ“‹ Files queue: ${filesList.join(', ')}`));
          
          // Show warning for large number of files
          if (totalFiles > 20) {
            console.log(chalk.yellow(`âš ï¸  Large number of files detected (${totalFiles}). This may take a while...`));
          }
          
          // Don't start spinner here - let the detailed logs show
      } else if (totalAnalyzedFiles > 0) {
          if (currentSpinner) currentSpinner.stop();
          const total = totalAnalyzedFiles + totalFilesToProcess;
          console.log(chalk.cyan(`\nğŸ“ˆ Progress: ${totalAnalyzedFiles}/${total} files analyzed`));
          
          if (totalFilesToProcess > 0) {
            console.log(chalk.blue(`ğŸ”„ Continuing with next file...`));
          } else {
            console.log(chalk.green(`ğŸ¯ All files analyzed, generating final report...`));
          }
      }

      console.log(chalk.gray(`ğŸ’¾ Updating database state...`));
      // Update state in DB with accumulated state to preserve all file analyses
      await prisma.review.update({
        where: { id: taskId },
        data: { state: lastState },
      });
    }
  } catch (error: any) {
    if (currentSpinner) currentSpinner.fail();
    
    // Handle recursion limit error specifically
    if (error.lc_error_code === 'GRAPH_RECURSION_LIMIT') {
      const analyzedFilesCount = Object.keys(lastState.analyzed_files || {}).length;
      const fileResultsCount = Object.keys(lastState.file_results || {}).length;
      const totalAnalyzed = analyzedFilesCount + fileResultsCount;
      
      console.error(chalk.red(`\nâŒ Workflow hit recursion limit while processing files.`));
      console.error(chalk.yellow(`ğŸ”§ This usually happens with a large number of files (${totalAnalyzed} files processed so far).`));
      console.error(chalk.blue(`ğŸ’¡ Consider breaking down the PR into smaller commits or contact support.`));
      
      const analyzedFilesList = [
        ...Object.keys(lastState.analyzed_files || {}),
        ...Object.keys(lastState.file_results || {})
      ];
      const remainingFilesList = [
        ...(lastState.files_to_review || []),
        ...(lastState.files_to_process || [])
      ];
      
      console.error(chalk.gray(`ğŸ“‹ Files already analyzed: ${analyzedFilesList.join(', ')}`));
      console.error(chalk.gray(`ğŸ“‹ Files remaining: ${remainingFilesList.join(', ')}`));
    } else {
      console.error(chalk.red(`\nâŒ Error during review process: ${error.message || error}`));
    }
    
    // Save the current state even on error
    try {
      await prisma.review.update({
        where: { id: taskId },
        data: { 
          state: lastState,
          error: error.message || String(error)
        },
      });
    } catch (dbError) {
      console.error(chalk.red(`âŒ Additional error saving state to database: ${dbError}`));
    }
    
    return; // Exit early on error
  }

  if (currentSpinner) currentSpinner.succeed();
  
  console.log(chalk.bold.green(`\nğŸ‰ Analysis Complete!`));
  console.log(chalk.blue(`â±ï¸  Task ID for future reference: ${chalk.yellow(taskId)}`));
  
  // Show file analysis database summary
  try {
    const fileAnalysisCount = await prisma.fileAnalysis.count({
      where: { reviewId: taskId }
    });
    console.log(chalk.blue(`ğŸ’¾ Individual file analyses saved to database: ${chalk.yellow(fileAnalysisCount)}`));
    console.log(chalk.gray(`ğŸ’¡ View file analyses: ${chalk.cyan(`hikma reports files ${taskId}`)}`));
  } catch (error) {
    console.log(chalk.yellow(`âš ï¸  Could not verify file analysis count in database`));
  }
  
  // Generate and save markdown report
  console.log(chalk.blue(`\nğŸ“„ Generating markdown report...`));
  try {
    const markdown = generateMarkdownReport(lastState, taskId, prUrl);
    const reportPath = saveMarkdownReport(markdown, prUrl, taskId);
    console.log(chalk.green(`âœ… Report saved to: ${chalk.yellow(reportPath)}`));
    
    // Show relative path for easier access
    const relativePath = path.relative(process.cwd(), reportPath);
    console.log(chalk.blue(`ğŸ“ View your report: ${chalk.cyan(`cat "${relativePath}"`)}`));
    console.log(chalk.blue(`ğŸ”— Or open in editor: ${chalk.cyan(`code "${relativePath}"`)}`));
  } catch (error) {
    console.error(chalk.red(`âŒ Error saving markdown report: ${error}`));
  }
  
  console.log(chalk.bold.magenta('\n' + '='.repeat(60)));
  console.log(chalk.bold.magenta('ğŸ“Š HIKMAPR PR REVIEW REPORT'));
  console.log(chalk.bold.magenta('='.repeat(60)));
  console.log(lastState.final_report);
  console.log(chalk.bold.magenta('='.repeat(60)));
};
